{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\internship project\\\\dataset\\\\Garbage classification\\\\Garbage classification'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\internship project\\\\dataset\\\\Garbage classification\\\\Garbage classification'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/user/Desktop/internship project/dataset/Garbage classification/Garbage classification\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Convolution Layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size = (6, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Flattening Layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Hidden Layer\n",
    "model.add(Dense(init=\"uniform\",activation=\"relu\",output_dim=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=6, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Output layer\n",
    "model.add(Dense(init=\"uniform\",activation=\"sigmoid\",output_dim=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1766 images belonging to 6 classes.\n",
      "Found 762 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r'C:\\Users\\user\\Desktop\\internship project\\dataset\\train data',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                     class_mode = 'categorical')\n",
    "x_test = test_datagen.flow_from_directory(r'C:\\Users\\user\\Desktop\\internship project\\dataset\\test data',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cardboard': 0, 'glass': 1, 'metal': 2, 'paper': 3, 'plastic': 4, 'trash': 5}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1994/3000 [==================>...........] - ETA: 4:31 - loss: 0.0682 - accuracy: 0.9754"
     ]
    }
   ],
   "source": [
    "model.fit_generator(x_train,\n",
    "                         steps_per_epoch = 3000,\n",
    "                         epochs = 5,\n",
    "                         validation_data = x_test,\n",
    "                         validation_steps = 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=10, validation_data=<keras.pre..., validation_steps=32, steps_per_epoch=4)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0977 - accuracy: 0.9661 - val_loss: 0.3718 - val_accuracy: 0.8975\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.1072 - accuracy: 0.9596 - val_loss: 0.4822 - val_accuracy: 0.8883\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0935 - accuracy: 0.9701 - val_loss: 0.2839 - val_accuracy: 0.8964\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0717 - accuracy: 0.9788 - val_loss: 0.5257 - val_accuracy: 0.8862\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0693 - accuracy: 0.9714 - val_loss: 0.3364 - val_accuracy: 0.8903\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0849 - accuracy: 0.9688 - val_loss: 0.4786 - val_accuracy: 0.8979\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0880 - accuracy: 0.9648 - val_loss: 0.2168 - val_accuracy: 0.8998\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 6s 2s/step - loss: 0.0887 - accuracy: 0.9714 - val_loss: 0.4252 - val_accuracy: 0.8942\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1051 - accuracy: 0.9570 - val_loss: 0.3436 - val_accuracy: 0.8939\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.0810 - accuracy: 0.9740 - val_loss: 0.3505 - val_accuracy: 0.8934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2836166ee08>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train, samples_per_epoch=128, epochs=10, validation_data=x_test,validation_steps=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model('mymodel.h5')\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img = resize(frame,(64,64))\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img = img/255.0\n",
    "        prediction = model.predict(img)\n",
    "        print(prediction)\n",
    "        prediction = model.predict_classes(img)\n",
    "        print(prediction)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.2181653e-06 9.5780426e-01 3.6814986e-03 3.8392642e-05 1.0800052e-02\n",
      "  0.0000000e+00]]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread('C:/Users/chait/OneDrive/Desktop/Dataset/Garbage classification/glass/glass1.jpg')\n",
    "data = detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.7315934e-06 8.9004450e-02 3.0659984e-03 7.1855158e-07 9.7744137e-01\n",
      "  0.0000000e+00]]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread('C:/Users/chait/OneDrive/Desktop/Dataset/Garbage classification/paper/paper1.jpg')\n",
    "data = detect(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
